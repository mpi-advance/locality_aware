#!/bin/sh
#Submit using flux batch <filename>

#flux: --job-name=allreduce_plus_copy_cpx_n32
#flux: --output='allreduce_plus_copy_cpx_n32.{{id}}.out'
#flux: --error='allreduce_plus_copy_cpx_n32.{{id}}.err'
#flux: -N 32
#flux: -l # Add task rank prefixes to each line of output.
#flux: --setattr=thp=always # Enable Transparent Huge Pages (THP)
#flux: -t 30
#flux: -q pbatch
#flux: -x
#flux: --setattr=gpumode=CPX
#flux: --conf=resource.rediscover=true

module load rocmcc/6.4.0-magic
module load cce/19.0.0
module load cray-mpich/9.0.1

export MPICH_GPU_SUPPORT_ENABLED=1
export HSA_XNACK=1

# Check if THP are enabled
#cat /sys/kernel/mm/transparent_hugepage/enabled

cd $HOME/MPICCL/build_cpx/benchmarks

n_nodes=32
gpus_per_node=24
max_cores=4

for ppg in 1 2 4; do
  n_procs=$(( ppg * gpus_per_node * n_nodes ))
  n_cores=$(( max_cores / ppg ))
  echo "${ppg} Processes Per GPU, ${gpus_per_node} GPUs Per Node"
  if [ "$ppg" -eq 1 ]; then
    flux run -N${n_nodes} -n${n_procs} -c${n_cores} --verbose --exclusive\
        --setopt=mpibind=verbose:2 ./allreduce
  else
    flux run -N${n_nodes} -n${n_procs} -c${n_cores} --verbose --exclusive\
        --setopt=mpibind=verbose:2 ./allreduce_copy
  fi
done
